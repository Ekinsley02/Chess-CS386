# Introduction
Provide 1-2 paragraphs to describe your system. This description should contain the value proposition and the main features. At the end of the introduction, include a link to your project on GitHub.
Grading criteria (1 point): This section will be evaluated in terms of correctness, completeness, thoroughness, consistency, coherence, and adequate use of language. The description should be consistent with the current state of the project. You should include the link to GitHub.
# Implemented requirements
List in this section the requirements and associated pull request that you implemented for this release, following the example below---include the description of the requirement, a link to the issue,  a link to the pull request(s) that implement the requirement, who implemented the requirement, who approved it, and a print screen that depicts the implemented feature (if applicable). Order the requirements by the name of the student who implemented them. Everyone in the group is expected to have code contributions documented by means of pull requests. Every pull request should be reviewed and approved before the merge.
At this point, we expect that you implement/prototype the features you specified in your MVP (c.f. D.2 Requirements). Pivots and changes are allowed as soon as you justify them.
See the example:
Requirement: As a Student, I want to add a homework assignment so that I can organize my ToDo list.
**Issue:**
<link to your GitHub issue>
**Pull request:**
https://github.com/user/project/pull/426
Links to an external site.
**Implemented by:**
Martin Fowler
**Approved by:**
Ada Lovelace
**Print screen:**
A print screen that depicts the implemented feature (if applicable)

Remember that all code contributions should be submitted via pull requests and the reviewer should review and approve each pull request.
Grading criteria (20 points): This section will be evaluated in terms of correctness, completeness, thoroughness, consistency, coherence, adequate use of language, and amount of work put into the implementation. Students can receive different grades depending on their involvement. It is expected that all members contribute with non-trivial implementation. All pull requests should be approved and integrated by the scrum master. You should follow an adequate workflow (description of the requirement on the issue tracker, submission of the implemented requirement as a pull request, and review of the pull request by another developer).
# Tests
## Unit tests
A unit test is an automated test that aims to verify the behavior of a component isolated from the rest of the system. For this deliverable, show an example of a unit test that uses mock objects to isolate the class from the rest of the system.
Test framework you used to develop your tests (e.g., JUnit, unittest, pytest, etc.)
Link to your GitHub folder where your automated unit tests are located
An example of a test case that makes use of mock objects. Include in your answer a GitHub link to the class being tested and to the test
A print screen showing the result of the unit test execution
Grading criteria (2 points): adequate choice of a test framework, coverage of the tests, quality of the tests, adequate use of Mock objects, and a print screen showing successful test execution.
3.2 Acceptance tests
An acceptance test is a test that verifies the correct implementation of a feature from the user interface perspective. An acceptance test is a black box test (the system is tested without knowledge about its internal implementation). Provide the following information:
Test framework you used to develop your tests (e.g., Selenium, Katalon Studio, Espresso2, Cucumber, etc.)
Link to your GitHub folder where your automated acceptance tests are located
An example of an acceptance test. Include a GitHub link to the test and an explanation about the tested feature in your answer.
A print screen/video showing the acceptance test execution
Grading criteria (2 points): adequate choice of a test framework, coverage of the tests, quality of the tests, adequate example of an acceptance test, print screen/video showing successful test execution.
4. Demo
   Include a link to a video showing the system working.
   Grading criteria (10 points): This section will be graded based on the quality of the video and on the evidence that the features are running as expected. Additional criteria are the relevance of the demonstrated functionalities, the correctness of the functionalities, and the quality of the developed system from the external point of view (user interface).
5. Code quality
   Describe how your team managed code quality. What were your policies, conventions, adopted best practices, etc., to foster high-quality code?
   Grading criteria (3 points): Adequate list of practices that were adopted to improve code quality and clear description with adequate use of language.
6. Lessons learned
   In retrospect, describe what your team learned during this second release and what you would change if you would continue developing the project.
   Grading criteria (2 points): Adequate reflection about problems and solutions, clear description with adequate use of language.

# Project Documentation

## 1. Introduction
Our system is a desktop chess application that uses a wide variety of technologies from C for the backend to Python/PyGame for the graphics to SQLite databases hosted in the cloud for data storage. The system has a graphical user interface where the user can select between pass-and-play functionality as well as some other game modes that are potentially coming soon such as cloud gaming and an AI teacher for people who don't know how to play chess.  
The system is snappy and responsive due to much of the game logic being written in C. The game runs at a consistent 60 frames per second while using minimum system resources so it can be played on slower systems without a problem.

[GitHub Repository Link](https://github.com/Ekinsley02/Chess-CS386)

## 2. Implemented Requirements

## 2.a
**Requirement:** As a player, I want to play a game of chess against another player so that I can enjoy a competitive match
Requirement: As a player, I want to play a game of chess against another player so that I can enjoy a competitive match
**Issue:**
https://github.com/Ekinsley02/Chess-CS386/issues/2
**Pull request:**
https://github.com/Ekinsley02/Chess-CS386/pull/52
**Implemented by:**
Noah Carges
**Approved by:**
Tristen Calder
**Print screen:**
![UI](https://media.discordapp.net/attachments/1278784448514625651/1310473363256508476/image.png?ex=674558ed&is=6744076d&hm=5de26364839df3670a38cd1e54676caaaf421ce85fbccd0eeab2721c14fd9419&=&format=webp&quality=lossless&width=891&height=920)

## 2.b
**Requirement:** As a player I want to be able to create my own account and be able to login to see my past games
Requirement: As a player I want to be able to create my own account and be able to login to see my past games
**Issue:**
https://github.com/Ekinsley02/Chess-CS386/issues/62
**Pull request:**
https://github.com/Ekinsley02/Chess-CS386/pull/61
**Implemented by:**
Ryan Todd
**Approved by:**
Tristen Calder
**Print screen:**
![Account Login](https://media.discordapp.net/attachments/1278784448514625651/1310473530130956318/image.png?ex=67455915&is=67440795&hm=dc20929001c2652eab7aa4107c6c1f6043c88a73aed2ec29ed0a45f9fc1de74c&=&format=webp&quality=lossless&width=1440&height=765)

## 2.c
Requirement: “As a player, I want the chessboard and UI to be visually appealing so that I have an enjoyable and engaging experience while playing.”
**Issue:** https://github.com/Ekinsley02/Chess-CS386/issues/15
**Issue:**
https://github.com/Ekinsley02/Chess-CS386/issues/15
**Pull request:**
https://github.com/Ekinsley02/Chess-CS386/pull/58
**Implemented by:**
Elliot Kinsley
**Approved by:**

Requirement: “ In terms of technology, the only requirement is to adopt a client-server architecture and use a database system. You need some server-side code and data storage”
**Issue:** https://github.com/Ekinsley02/Chess-CS386/issues/63
**Pull request:** https://github.com/Ekinsley02/Chess-CS386/pull/67
**Implemented by:** Tristen Calder
**Approved by:** Tristen Calder
**Print screen:**
![Server-side Architecture](https://media.discordapp.net/attachments/1278784448514625651/1310473725618950144/image.png?ex=67455943&is=674407c3&hm=6f32ac9577b1c424ba8e6380f32985678dd68652d9b49bb75b6f69a2b0886f13&=&format=webp&quality=lossless&width=1144&height=287)


## 3. Tests

### 3.1 Unit Tests
A unit test is an automated test that aims to verify the behavior of a component isolated from the rest of the system. For this deliverable, show an example of a unit test that uses mock objects to isolate the class from the rest of the system.

- Test framework you used to develop your tests (e.g., JUnit, unittest, pytest, etc.)
    - unittest

- Link to your GitHub folder where your automated unit tests are located
    - [Workflow Folder] (https://github.com/Ekinsley02/Chess-CS386/tree/main/.github/workflows)
    - [Test Folder](https://github.com/Ekinsley02/Chess-CS386/blob/main/tests)

- An example of a test case that makes use of mock objects. Include in your answer a GitHub link to the class being tested and to the test
    - [Castling test] (https://github.com/Ekinsley02/Chess-CS386/blob/main/tests/test_castling.py)
    - This script is a unit test that uses unittest to automate the testing of queenside castling in a chess engine. It initializes a chess engine, simulates a series of moves leading up to a castling maneuver, and verifies the correct execution of each move. The script checks for proper piece selection, movement validation, and ensures the chess engine's board state matches expected results.


- A screenshot showing the result of the unit test execution
![Unit Test Execution Result](https://gcdnb.pbrd.co/images/Bb8YG5lM169a.png?o=1)
    - The current tests are not correct, however, the program works. Will be updated.

### 3.2 Acceptance Tests
An acceptance test is a test that verifies the correct implementation of a feature from the user interface perspective. An acceptance test is a black box test (the system is tested without knowledge about its internal implementation). Provide the following information:

- Test framework you used to develop your tests (e.g., Selenium, Katalon Studio, Espresso2, Cucumber, etc.)
    - pyautogui

- Link to your GitHub folder where your automated acceptance tests are located
    - [Workflow Folder] (https://github.com/Ekinsley02/Chess-CS386/tree/main/.github/workflows)
    - [Test Folder] (https://github.com/Ekinsley02/Chess-CS386/blob/main/automated_tests)

- An example of an acceptance test. Include a GitHub link to the test and an explanation about the tested feature in your answer.
    - [Acceptance Test] (https://github.com/strictlyrare/Chess-CS386/blob/main/acceptance_tests/test_user_login.py)
    - This Python script uses unittest and pyautogui to automate testing of a user login feature in a Pygame application. It interacts with the login GUI by simulating mouse clicks and keyboard input for both valid and invalid login attempts, ensuring the application handles these correctly. The script manages the Pygame application as a subprocess and checks if it continues to run or exits unexpectedly during the tests.


- A screenshot/video showing the acceptance test execution
![Acceptance Test Execution Result](https://gcdnb.pbrd.co/images/YlvLmQN7Rlzz.png?o=1)

## 4. Demo
Include a link to a video showing the system working.  
[Video Demo](https://youtu.be/jKw09Ix0Jyk)

## 5. Code Quality
Describe how your team managed code quality. What were your policies, conventions, adopted best practices, etc., to foster high-quality code?

Our team managed code quality by commenting all code in a way that would make sense to someone that didn't work on that section of code. We attempted to keep the comments descriptive to the point where you could hit ctrl+F and search by comment if you were looking for some code. To do that we made sure to have obvious keywords in the comments and have them spelled correctly.

We also made sure to adhere to a rigid code review process where manual checks would be run by the group leaders, Elliott and Noah who pushed everybody’s code to the GitHub where it was reviewed by someone else to ensure we have multiple people looking over all code. In addition to automatic tests, manual checks were also run on the code, mainly by playing the chess game to ensure it worked as expected.

## 6. Lessons Learned
In retrospect, describe what your team learned during this second release and what you would change if you would continue developing the project.

The main thing we learned is we always want to keep adding on to our project. Everytime we write code we come up with new ideas on how to make the project better and add more features. We also learned throughout the semester that Discord calls where we can just chat about what we are working on without waiting for a text reply boosts productivity massively. Being able to share your screen, explain the code you just wrote and ask for feedback is massively valuable for team collaboration.


